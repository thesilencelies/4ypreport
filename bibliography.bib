
@article{RVA,
  author    = {Volodymyr Mnih and
               Nicolas Heess and
               Alex Graves and
               Koray Kavukcuoglu},
  title     = {Recurrent Models of Visual Attention},
  journal   = {CoRR},
  volume    = {abs/1406.6247},
  year      = {2014},
  url       = {http://arxiv.org/abs/1406.6247},
  timestamp = {Tue, 01 Jul 2014 11:58:08 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/MnihHGK14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
@article{JAStarzyk08,

author = {  Janusz A. Starzyk and 
		Yinyin Liu and 
		Sebastian Batog},
title = {A Novel Optimization Algorithm Based on Reinforcement Learning},
 year =  {2008}
 url ={ http://www.ohio.edu/people/starzykj/network/research/Papers/CIEOP_BookChapter_RLO_Final.pdf}
}
@inbook {NIPS2008_0447,
	title = {Optimization on a Budget: A Reinforcement Learning Approach},
	booktitle = {Advances in Neural Information Processing Systems 21},
	series = {NIPS-08},
	year = {2009},
	month = {December},
	pages = {1385{\textendash}1392},
	author = {Paul L Ruvolo and Ian Fasel and Javier Movellan},
	editor = {D. Koller and D. Schuurmans and Y. Bengio and L. Bottou}
}
@Article{Williams04,
author="Williams, Ronald J.",
title="Simple statistical gradient-following algorithms for connectionist reinforcement learning",
journal="Machine Learning",
volume="8",
number="3",
pages="229--256",
abstract="This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms.",
issn="1573-0565",
doi="10.1007/BF00992696",
url="http://dx.doi.org/10.1007/BF00992696"
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={ICML},
  year={2014}
}

@Inbook{Cu√©llar2006,
author="Cu{\'e}llar, M.P.
and Delgado, M.
and Pegalajar, M.C.",
editor="Chen, Chin-Sheng
and Filipe, Joaquim
and Seruca, Isabel
and Cordeiro, Jos{\'e}",
chapter="AN APPLICATION OF NON-LINEAR PROGRAMMING TO TRAIN RECURRENT NEURAL NETWORKS IN TIME SERIES PREDICTION PROBLEMS",
title="Enterprise Information Systems VII",
year="2006",
publisher="Springer Netherlands",
address="Dordrecht",
pages="95--102",
isbn="978-1-4020-5347-4",
doi="10.1007/978-1-4020-5347-4_11",
url="http://dx.doi.org/10.1007/978-1-4020-5347-4_11"
}

@article{alphaGo,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={Nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{mnih2016asynchronous,
  title={Asynchronous Methods for Deep Reinforcement Learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1602.01783},
  year={2016}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}
@article{pascanu2012difficulty,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1211.5063},
  year={2012}
}

@article{levine2015end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1504.00702},
  year={2015}
}

@article{atariDQN,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{ling2016latent,
  title={Latent Predictor Networks for Code Generation},
  author={Ling, Wang and Grefenstette, Edward and Hermann, Karl Moritz and Kocisky, Tomas and Senior, Andrew and Wang, Fumin and Blunsom, Phil},
  journal={arXiv preprint arXiv:1603.06744},
  year={2016}
}

@book{Sutton:1998:IRL:551283,
 author = {Sutton, Richard S. and Barto, Andrew G.},
 title = {Introduction to Reinforcement Learning},
 year = {1998},
 isbn = {0262193981},
 edition = {1st},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 
@misc{numinsightblog,
   author = "Shashi Sathyanarayana",
   title = {A Gentle Introduction to Backpropagation},
   url = {http://numericinsight.blogspot.co.uk/2014/07/a-gentle-introduction-to-backpropagation.html},
   year = "2016"
}

@misc{rnnslides,
   author = "Ilya Kuzovkin",
   title = {Article overview: Unsupervised Learning of Visual Structure Using Predictive Generative Networks},
  % url = {http://www.slideshare.net/iljakuzovkin/article-overview-unsupervised-learning-of-visual-structure-using-predictive-generative-networks},
  note = "[Online, accessed 21-Feb-2016]",
   year = "2016"
}

@misc{rnnblog,
    author = "Andrej Karpathy",
    title = {"the unreasonable effectiveness of recurrent neural networks"},
    url = {http://karpathy.github.io/2015/05/21/rnn-effectiveness/},
    year = {2016}
}

@misc{Torch:RVA,
	author = "Nicolas Leonard, Element Research",
	title = {"Torch blog : Recurrent Model of Visual Attention"},
	url = {http://torch.ch/blog/2015/09/21/rmva.html},
	year = {2016}
}

@misc{generic,
	author = "",
	title = {""},
	url = {},
	year = {2016}
}

