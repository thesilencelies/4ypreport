\section{Introduction}
  %what is this about
This report details the research the author did in the academic year 2015-16 concerning reinforcement learning and it's uses. The initial goal of the project was to develop an AI that would be able to play some form of video game using reinforcement learning and neural networks as function approximators. However, halfway through an potentially more fruitful line of research opened up, and the project was redirected to consider how to develop a reinforcement learning agent that can optimize any given function in a minimum of steps.

The primary results of this research are an exploration of the limits of current technology to parse complex situations and produce meaningful behaviour, and in particular the limitations of using Reinforcement learning to train neural networks for control in such tasks.

\subsection{Context}
  %why do we care?
Beyond immediate applications in terms of producing better quality AI for video games themselves, such research is really helpful to a number of different areas. The work in \cite{atariDQN} was used to develop an end to end training system for visual control for a robot attempting a number of difficult tasks in \cite{levine2015end}, and further advances in reinforcement learning would quickly find application in a number of different areas of robotics. The work on function optimisation in particular has several direct uses, as well as the indirect gains in terms of control and comprehension in a sequentially observed continuous environment. For example, such an optimiser could be used to quickly find the optimal hyper parameter settings for  a neural network, a task for which currently Bayesian optimisation is used.

\subsection{Objectives}
%what are we trying to do?
The primary aim of the research in this paper was to develop an agent that trained neural networks using reinforcement learning to perform the task in hand, be that playing a card game or producing the minimum of some given black box function. Within this objective are the sub-goals of gaining a comprehensive understanding of the current state of the art within reinforcement learning, and learning the arcane tricks required to be able to train deep neural networks.

As a secondary objective, it would be desirable to gain further technical understanding about what a neural network can and cannot learn, as well as potentially developing an architecture upon which further research can easily be added.

\subsection{Report structure}
%how the rest of the report flows
This report is organised broadly into two sections, exploring the research into game playing agents and function optimisers respectively. Within each section, the specific implementations and associated challenges are detailed, as well as any experimental results gathered.